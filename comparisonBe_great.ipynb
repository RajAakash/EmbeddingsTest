{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5048247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05547201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read real data\n",
    "df=pd.read_csv('Original_embeddings/kripkeOutput.csv')\n",
    "X_real=df.drop(columns=['relative_runtime'])\n",
    "y_real=df['relative_runtime']\n",
    "\n",
    "# Read MIN generated Data\n",
    "df=pd.read_csv('MIN_embeddings/kripke_MIN.csv')\n",
    "X_min=df.drop(columns=['relative_runtime'])\n",
    "y_min=df['relative_runtime']\n",
    "\n",
    "# Read be_great generated data\n",
    "df1=pd.read_csv('be_greatEmbeddings/kripke_beGreat.csv')\n",
    "X_beGreat=df1.drop(columns=['relative_runtime'])\n",
    "y_beGreat=df1['relative_runtime']\n",
    "\n",
    "# Read be_great generated data\n",
    "df1=pd.read_csv('CTGAN_embeddings/kripke_CTGAN.csv')\n",
    "X_ctgan=df1.drop(columns=['relative_runtime'])\n",
    "y_ctgan=df1['relative_runtime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d390a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 65)\n",
      "(210,)\n"
     ]
    }
   ],
   "source": [
    "print(X_real.shape)\n",
    "print(y_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fcdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
    "    X_real, y_real, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e40876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_real_train)\n",
    "\n",
    "X_real_train = scaler.transform(X_real_train)\n",
    "X_real_test  = scaler.transform(X_real_test)\n",
    "X_ctgan      = scaler.transform(X_ctgan)\n",
    "X_min        = scaler.transform(X_min)\n",
    "X_beGreat    = scaler.transform(X_beGreat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d03a0",
   "metadata": {},
   "source": [
    "## Maximum Mean Discrepancy\n",
    "#### It tests the difference between the real and generated data distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1a62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05716934221972658\n",
      "0.2008693647029487\n",
      "0.3438467085717972\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def compute_mmd(X, Y, gamma=None):\n",
    "    if gamma is None:\n",
    "        gamma = 1.0 / X.shape[1]\n",
    "\n",
    "    K_xx = rbf_kernel(X, X, gamma=gamma)\n",
    "    K_yy = rbf_kernel(Y, Y, gamma=gamma)\n",
    "    K_xy = rbf_kernel(X, Y, gamma=gamma)\n",
    "\n",
    "    return K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
    "\n",
    "mmd_ctgan = compute_mmd(X_real_test, X_ctgan)\n",
    "mmd_min   = compute_mmd(X_real_test, X_min)\n",
    "mmd_beGreat=compute_mmd(X_real_test,X_beGreat)\n",
    "print(mmd_ctgan)\n",
    "print(mmd_min)\n",
    "print(mmd_beGreat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d69d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 65)\n",
      "(500, 65)\n",
      "(10, 65)\n"
     ]
    }
   ],
   "source": [
    "print(X_real_test.shape)\n",
    "print(X_ctgan.shape)\n",
    "print(X_beGreat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96141f3a",
   "metadata": {},
   "source": [
    "# Co-relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93cb6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "X_real_f = vt.fit_transform(X_real_test)\n",
    "X_ctgan_f = vt.transform(X_ctgan)\n",
    "X_min_f = vt.transform(X_min)\n",
    "X_beGreat_f=vt.transform(X_beGreat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff265e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_error(X_real, X_gen):\n",
    "    mean_err = np.mean(np.abs(X_real.mean(axis=0) - X_gen.mean(axis=0)))\n",
    "    std_err  = np.mean(np.abs(X_real.std(axis=0)  - X_gen.std(axis=0)))\n",
    "    return mean_err, std_err\n",
    "\n",
    "mean_ctgan, std_ctgan   = marginal_error(X_real_f, X_ctgan_f)\n",
    "mean_min,   std_min     = marginal_error(X_real_f, X_min_f)\n",
    "mean_beGreat,std_beGreat= marginal_error(X_real_f,X_beGreat_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c03d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_columns(*arrays):\n",
    "    std = np.std(arrays[0], axis=0)\n",
    "    mask = std > 0\n",
    "    return [a[:, mask] for a in arrays]\n",
    "\n",
    "X_real_f, X_ctgan_f, X_min_f ,X_beGreat_f = remove_constant_columns(\n",
    "    X_real_f, X_real_f, X_min_f, X_beGreat_f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ecead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "10.297698458586014\n",
      "5.655544883697136\n"
     ]
    }
   ],
   "source": [
    "def corr_error(X_real, X_gen):\n",
    "    corr_real = np.corrcoef(X_real, rowvar=False)\n",
    "    corr_gen  = np.corrcoef(X_gen,  rowvar=False)\n",
    "    return np.linalg.norm(corr_real - corr_gen, ord='fro')\n",
    "\n",
    "corr_ctgan = corr_error(X_real_f, X_ctgan_f)\n",
    "corr_min   = corr_error(X_real_f, X_min_f)\n",
    "corr_beGreat = corr_error(X_real_f, X_beGreat_f)\n",
    "\n",
    "print(corr_ctgan)\n",
    "print(corr_min)\n",
    "print(corr_beGreat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85491b8",
   "metadata": {},
   "source": [
    "# TSTR (Train on Synthetic, Test on Real):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8af69e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': np.float64(0.5297977941547412), 'MAE': 0.42313490379209545, 'R2': -0.27194253895341425}\n",
      "{'RMSE': np.float64(0.7089765974007567), 'MAE': 0.6486178296349218, 'R2': -1.2777759348710553}\n",
      "{'RMSE': np.float64(0.43024165270371467), 'MAE': 0.2979784727746034, 'R2': 0.16117356796081073}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "def tstr_regression(X_syn, y_syn, X_real, y_real):\n",
    "    reg = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        random_state=42\n",
    "    )\n",
    "    reg.fit(X_syn, y_syn)\n",
    "    y_pred = reg.predict(X_real)\n",
    "\n",
    "    mse  = mean_squared_error(y_real, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return {\n",
    "        \"RMSE\": rmse,\n",
    "        \"MAE\": mean_absolute_error(y_real, y_pred),\n",
    "        \"R2\": r2_score(y_real, y_pred)\n",
    "    }\n",
    "\n",
    "res_ctgan   = tstr_regression(X_ctgan,   y_ctgan,   X_real_test, y_real_test)\n",
    "res_min     = tstr_regression(X_min,     y_min,     X_real_test, y_real_test)\n",
    "res_beGreat = tstr_regression(X_beGreat, y_beGreat, X_real_test, y_real_test)\n",
    "\n",
    "print(res_ctgan)\n",
    "print(res_min)\n",
    "print(res_beGreat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a831dbd",
   "metadata": {},
   "source": [
    "# Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5927d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def coverage(X_real, X_gen, epsilon):\n",
    "    nn = NearestNeighbors(n_neighbors=1).fit(X_gen)\n",
    "    distances, _ = nn.kneighbors(X_real)\n",
    "    return np.mean(distances < epsilon)\n",
    "\n",
    "coverage_ctgan    = coverage(X_real_test, X_ctgan, epsilon=2)\n",
    "coverage_min      = coverage(X_real_test, X_min,   epsilon=2)\n",
    "coverage_beGreat  = coverage(X_real_test, X_beGreat,   epsilon=2)\n",
    "print(coverage_ctgan)\n",
    "print(coverage_min)\n",
    "print(coverage_beGreat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b082a40",
   "metadata": {},
   "source": [
    "With epsilon=1, the MIN dataset shows better coverage than CTGAN, because:\n",
    "coverage is literally counting the fraction of real points that have a generated neighbor within distance 1.\n",
    "MIN achieves ~14% coverage, while CTGAN achieves 0%.(epilson=1 is strict coverage)\n",
    "So for this strict “pointwise closeness” metric, MIN data is “closer” to some real points than CTGAN.\n",
    "\n",
    "When epilson=1, I got 0.0 and 0.14 (which is really strict)\n",
    "\n",
    "When epilson=2, I got\n",
    "0.7142857142857143 and \n",
    "1.0\n",
    "But when I keep this to more than 1 like 5, both of them have coverage of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201cb084",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccbaf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def nn_distance_ratio(X_gen, X_real):\n",
    "    nn_real = NearestNeighbors(n_neighbors=1).fit(X_real)\n",
    "    d_real, _ = nn_real.kneighbors(X_gen)\n",
    "\n",
    "    nn_gen = NearestNeighbors(n_neighbors=2).fit(X_gen)\n",
    "    d_gen, _ = nn_gen.kneighbors(X_gen)\n",
    "\n",
    "    return np.mean(d_gen[:,1] / (d_real[:,0] + 1e-8))\n",
    "\n",
    "nn_ratio_ctgan     = nn_distance_ratio(X_ctgan, X_real_train)\n",
    "nn_ratio_min       = nn_distance_ratio(X_min,   X_real_train)\n",
    "nn_ratio_beGreat   = nn_distance_ratio(X_beGreat,   X_real_train)\n",
    "print(nn_ratio_ctgan)\n",
    "print(nn_ratio_min)\n",
    "print(nn_ratio_beGreat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6a4fb",
   "metadata": {},
   "source": [
    "# Privacy / Memorization Check\n",
    "\n",
    "Positive gap is expected in most synthetic data generators — they see the training data, so points tend to be closer to it.\n",
    "Smaller positive gap → generator generalizes better (less overfitting)\n",
    "\n",
    "Larger positive gap → generator may be memorizing training points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabf062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_nn_gap(X_gen, X_train, X_test):\n",
    "    nn_train = NearestNeighbors(n_neighbors=1).fit(X_train)\n",
    "    nn_test  = NearestNeighbors(n_neighbors=1).fit(X_test)\n",
    "\n",
    "    d_train, _ = nn_train.kneighbors(X_gen)\n",
    "    d_test,  _ = nn_test.kneighbors(X_gen)\n",
    "\n",
    "    return d_test.mean() - d_train.mean()\n",
    "\n",
    "gap_ctgan       = train_test_nn_gap(X_ctgan, X_real_train, X_real_test)\n",
    "gap_min         = train_test_nn_gap(X_min,   X_real_train, X_real_test)\n",
    "gap_beGreat     = train_test_nn_gap(X_beGreat,X_real_train, X_real_test)\n",
    "print(gap_ctgan)\n",
    "print(gap_min)\n",
    "print(gap_beGreat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
