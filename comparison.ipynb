{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5048247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05547201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read real data\n",
    "df=pd.read_csv('Original_embeddings/amgOutput.csv')\n",
    "X_real=df.drop(columns=['relative_runtime'])\n",
    "y_real=df['relative_runtime']\n",
    "\n",
    "# Read MIN generated Data\n",
    "df=pd.read_csv('MIN_embeddings/amg_MIN.csv')\n",
    "X_min=df.drop(columns=['relative_runtime'])\n",
    "y_min=df['relative_runtime']\n",
    "\n",
    "# Read CTGAN generated data\n",
    "df1=pd.read_csv('CTGAN_embeddings/amg_CTGAN.csv')\n",
    "X_ctgan=df1.drop(columns=['relative_runtime'])\n",
    "y_ctgan=df1['relative_runtime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d390a6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 64)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "print(X_real.shape)\n",
    "print(y_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fcdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_real_train, X_real_test, y_real_train, y_real_test = train_test_split(\n",
    "    X_real, y_real, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e40876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_real_train)\n",
    "\n",
    "X_real_train = scaler.transform(X_real_train)\n",
    "X_real_test  = scaler.transform(X_real_test)\n",
    "X_ctgan      = scaler.transform(X_ctgan)\n",
    "X_min        = scaler.transform(X_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70d03a0",
   "metadata": {},
   "source": [
    "## Maximum Mean Discrepancy\n",
    "#### It tests the difference between the real and generated data distrbution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1a62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06526087961720095\n",
      "0.015316886259179707\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def compute_mmd(X, Y, gamma=None):\n",
    "    if gamma is None:\n",
    "        gamma = 1.0 / X.shape[1]\n",
    "\n",
    "    K_xx = rbf_kernel(X, X, gamma=gamma)\n",
    "    K_yy = rbf_kernel(Y, Y, gamma=gamma)\n",
    "    K_xy = rbf_kernel(X, Y, gamma=gamma)\n",
    "\n",
    "    return K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
    "\n",
    "mmd_ctgan = compute_mmd(X_real_test, X_ctgan)\n",
    "mmd_min   = compute_mmd(X_real_test, X_min)\n",
    "print(mmd_ctgan)\n",
    "print(mmd_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d69d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 64)\n",
      "(500, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X_real_test.shape)\n",
    "print(X_ctgan.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96141f3a",
   "metadata": {},
   "source": [
    "# Co-relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93cb6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "X_real_f = vt.fit_transform(X_real_test)\n",
    "X_ctgan_f = vt.transform(X_ctgan)\n",
    "X_min_f = vt.transform(X_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff265e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginal_error(X_real, X_gen):\n",
    "    mean_err = np.mean(np.abs(X_real.mean(axis=0) - X_gen.mean(axis=0)))\n",
    "    std_err  = np.mean(np.abs(X_real.std(axis=0)  - X_gen.std(axis=0)))\n",
    "    return mean_err, std_err\n",
    "\n",
    "mean_ctgan, std_ctgan = marginal_error(X_real_f, X_ctgan_f)\n",
    "mean_min,   std_min   = marginal_error(X_real_f, X_min_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8c03d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_constant_columns(*arrays):\n",
    "    std = np.std(arrays[0], axis=0)\n",
    "    mask = std > 0\n",
    "    return [a[:, mask] for a in arrays]\n",
    "\n",
    "X_real_f, X_ctgan_f, X_min_f = remove_constant_columns(\n",
    "    X_real_f, X_real_f, X_min_f\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70ecead5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "9.424603277784783\n"
     ]
    }
   ],
   "source": [
    "def corr_error(X_real, X_gen):\n",
    "    corr_real = np.corrcoef(X_real, rowvar=False)\n",
    "    corr_gen  = np.corrcoef(X_gen,  rowvar=False)\n",
    "    return np.linalg.norm(corr_real - corr_gen, ord='fro')\n",
    "\n",
    "corr_ctgan = corr_error(X_real_f, X_ctgan_f)\n",
    "corr_min   = corr_error(X_real_f, X_min_f)\n",
    "\n",
    "print(corr_ctgan)\n",
    "print(corr_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85491b8",
   "metadata": {},
   "source": [
    "# TSTR (Train on Synthetic, Test on Real):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8af69e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n",
      "0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_real_test = y_real_test.astype(int)\n",
    "y_ctgan     = y_ctgan.astype(int)\n",
    "y_min       = y_min.astype(int)\n",
    "\n",
    "def tstr_accuracy(X_syn, y_syn, X_real, y_real):\n",
    "    clf = RandomForestClassifier(n_estimators=200)\n",
    "    clf.fit(X_syn, y_syn)\n",
    "    return accuracy_score(y_real, clf.predict(X_real))\n",
    "\n",
    "acc_ctgan = tstr_accuracy(X_ctgan, y_ctgan, X_real_test, y_real_test)\n",
    "acc_min   = tstr_accuracy(X_min,   y_min, X_real_test, y_real_test)\n",
    "print(acc_ctgan)\n",
    "print(acc_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a831dbd",
   "metadata": {},
   "source": [
    "# Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5927d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def coverage(X_real, X_gen, epsilon):\n",
    "    nn = NearestNeighbors(n_neighbors=1).fit(X_gen)\n",
    "    distances, _ = nn.kneighbors(X_real)\n",
    "    return np.mean(distances < epsilon)\n",
    "\n",
    "coverage_ctgan = coverage(X_real_test, X_ctgan, epsilon=1)\n",
    "coverage_min   = coverage(X_real_test, X_min,   epsilon=1)\n",
    "print(coverage_ctgan)\n",
    "print(coverage_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b082a40",
   "metadata": {},
   "source": [
    "With epsilon=1, the MIN dataset shows better coverage than CTGAN, because:\n",
    "coverage is literally counting the fraction of real points that have a generated neighbor within distance 1.\n",
    "MIN achieves ~14% coverage, while CTGAN achieves 0%.(epilson=1 is strict coverage)\n",
    "So for this strict “pointwise closeness” metric, MIN data is “closer” to some real points than CTGAN.\n",
    "\n",
    "When epilson=1, I got 0.0 and 0.14 (which is really strict)\n",
    "\n",
    "When epilson=2, I got\n",
    "0.7142857142857143 and \n",
    "1.0\n",
    "But when I keep this to more than 1 like 5, both of them have coverage of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201cb084",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ccbaf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6478466166660524\n",
      "0.0025078066843905564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def nn_distance_ratio(X_gen, X_real):\n",
    "    nn_real = NearestNeighbors(n_neighbors=1).fit(X_real)\n",
    "    d_real, _ = nn_real.kneighbors(X_gen)\n",
    "\n",
    "    nn_gen = NearestNeighbors(n_neighbors=2).fit(X_gen)\n",
    "    d_gen, _ = nn_gen.kneighbors(X_gen)\n",
    "\n",
    "    return np.mean(d_gen[:,1] / (d_real[:,0] + 1e-8))\n",
    "\n",
    "nn_ratio_ctgan = nn_distance_ratio(X_ctgan, X_real_train)\n",
    "nn_ratio_min   = nn_distance_ratio(X_min,   X_real_train)\n",
    "print(nn_ratio_ctgan)\n",
    "print(nn_ratio_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6a4fb",
   "metadata": {},
   "source": [
    "# Privacy / Memorization Check\n",
    "\n",
    "Positive gap is expected in most synthetic data generators — they see the training data, so points tend to be closer to it.\n",
    "Smaller positive gap → generator generalizes better (less overfitting)\n",
    "\n",
    "Larger positive gap → generator may be memorizing training points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4aabf062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017958328677955215\n",
      "0.027652122717660932\n"
     ]
    }
   ],
   "source": [
    "def train_test_nn_gap(X_gen, X_train, X_test):\n",
    "    nn_train = NearestNeighbors(n_neighbors=1).fit(X_train)\n",
    "    nn_test  = NearestNeighbors(n_neighbors=1).fit(X_test)\n",
    "\n",
    "    d_train, _ = nn_train.kneighbors(X_gen)\n",
    "    d_test,  _ = nn_test.kneighbors(X_gen)\n",
    "\n",
    "    return d_test.mean() - d_train.mean()\n",
    "\n",
    "gap_ctgan = train_test_nn_gap(X_ctgan, X_real_train, X_real_test)\n",
    "gap_min   = train_test_nn_gap(X_min,   X_real_train, X_real_test)\n",
    "print(gap_ctgan)\n",
    "print(gap_min)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
